{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmGezPDmY72K"
      },
      "source": [
        "# Tabular Prototype\n",
        "\n",
        "By Monday 6/30, make an attempt at formulating and \"solving\" your proposed problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hr11dQiY72U"
      },
      "source": [
        "## Machine Learning\n",
        "\n",
        "\n",
        "### Problem Formulation\n",
        "\n",
        "* Remove unneed columns, for example:\n",
        "    * duplicated\n",
        "    * categorical features that were turned into one-hot.\n",
        "    * features that identify specific rows, like ID number.\n",
        "    * make sure your target is properly encoded also.\n",
        "* Split training sample into train, validation, and test sub-samples.\n",
        "\n",
        "### Train ML Algorithm\n",
        "\n",
        "* You only need one algorithm for now. You can do more if you like.\n",
        "* For now, focus on making it work, rather than best result.\n",
        "* Try to get a non-trivial result.\n",
        "\n",
        "### Evaluate Performance on Validation Sample\n",
        "\n",
        "* Compute the usual metric for your ML task.\n",
        "* Compute the score for the kaggle challenge.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xjKTVnj7Y72W"
      },
      "outputs": [],
      "source": [
        "#From the previous notebook\n",
        "\n",
        "from preprocessing import load_and_preprocess\n",
        "X_scaled, y = load_and_preprocess('cleaned_student_data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dW-PmNutxz18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem Formulation\n",
        "Data Cleaning & Preparation(Already solved in the previous notebook: Feasibility)\n",
        "\n",
        "* Missing values? ‚Äî None (Missing: 0)\n",
        "* Duplicates? ‚Äî None (Duplicates: 0)\n",
        "* Scaling? ‚Äî Numerical features scaled with StandardScaler\n",
        "* Features cleaned? ‚Äî Dropped StudentID and any unimportant columns\n",
        "* Target prepared? ‚Äî GradeClass is an integer label (0‚Äì4)\n",
        "* Features numeric? ‚Äî Yes ‚Äî all numeric, perfect for scikit-learn\n",
        "* Feature/target shapes? ‚Äî X_scaled.shape: (2392, 13) and y.shape: (2392,)\n"
      ],
      "metadata": {
        "id": "XNqJcAqsvnFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train ML Algorithm"
      ],
      "metadata": {
        "id": "Qsc8IBZEww4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80/20 split into train/val and test\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Split train/val into 75/25\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_trainval, y_trainval, test_size=0.25, stratify=y_trainval, random_state=42\n",
        ")\n",
        "\n",
        "print('Train:', X_train.shape, 'Val:', X_val.shape, 'Test:', X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv5byDObZ-dc",
        "outputId": "615182e6-1eeb-44da-9633-040804160135"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (1434, 13) Val: (479, 13) Test: (479, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Performance on Validation Sample"
      ],
      "metadata": {
        "id": "-a_1TF-a26hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First Try\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# Fit a RandomForest baseline\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_val_pred = model.predict(X_val)\n",
        "\n",
        "# Metrics\n",
        "acc = accuracy_score(y_val, y_val_pred)\n",
        "f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
        "cm = confusion_matrix(y_val, y_val_pred)\n",
        "\n",
        "print('Validation Accuracy:', acc)\n",
        "print('Validation F1-score:', f1)\n",
        "print('\\nConfusion Matrix:\\n', cm)\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_val_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NP1WNmWbpkJ",
        "outputId": "0a7afff5-ff88-4773-97ac-0d1ddb79f08b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.906054279749478\n",
            "Validation F1-score: 0.9036485031207436\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 15   1   2   2   2]\n",
            " [  1  42   0   1  10]\n",
            " [  1   3  67   1   6]\n",
            " [  0   2   3  70   8]\n",
            " [  0   1   0   1 240]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.68      0.77        22\n",
            "           1       0.86      0.78      0.82        54\n",
            "           2       0.93      0.86      0.89        78\n",
            "           3       0.93      0.84      0.89        83\n",
            "           4       0.90      0.99      0.94       242\n",
            "\n",
            "    accuracy                           0.91       479\n",
            "   macro avg       0.90      0.83      0.86       479\n",
            "weighted avg       0.91      0.91      0.90       479\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second Try\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_val_pred = model.predict(X_val)\n",
        "\n",
        "# Compute metrics\n",
        "acc = accuracy_score(y_val, y_val_pred)\n",
        "precision = precision_score(y_val, y_val_pred, average='weighted')\n",
        "recall = recall_score(y_val, y_val_pred, average='weighted')\n",
        "f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
        "\n",
        "# Print results\n",
        "print(f'Validation Accuracy:  {acc:.3f}')\n",
        "print(f'Validation Precision: {precision:.3f}')\n",
        "print(f'Validation Recall:    {recall:.3f}')\n",
        "print(f'Validation F1-score:  {f1:.3f}\\n')\n",
        "\n",
        "# Detailed report\n",
        "print('Classification Report:\\n')\n",
        "print(classification_report(y_val, y_val_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD9ne8WucBcU",
        "outputId": "2b9faa00-0df7-4d54-fd4e-afe6e7e8cfaf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  0.906\n",
            "Validation Precision: 0.906\n",
            "Validation Recall:    0.906\n",
            "Validation F1-score:  0.904\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.68      0.77        22\n",
            "           1       0.86      0.78      0.82        54\n",
            "           2       0.93      0.86      0.89        78\n",
            "           3       0.93      0.84      0.89        83\n",
            "           4       0.90      0.99      0.94       242\n",
            "\n",
            "    accuracy                           0.91       479\n",
            "   macro avg       0.90      0.83      0.86       479\n",
            "weighted avg       0.91      0.91      0.90       479\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Compute final metrics\n",
        "print(\"üîç Final Evaluation on Test Set:\")\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_test_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred, average='weighted'))\n",
        "print(\"Recall:   \", recall_score(y_test, y_test_pred, average='weighted'))\n",
        "print(\"F1 Score: \", f1_score(y_test, y_test_pred, average='weighted'))\n",
        "\n",
        "# Full report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as8O-OvOx1F9",
        "outputId": "a9d34aab-cb7a-4724-aaf2-7ba627710e8e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Final Evaluation on Test Set:\n",
            "Accuracy:  0.9144050104384134\n",
            "Precision: 0.9168888520318789\n",
            "Recall:    0.9144050104384134\n",
            "F1 Score:  0.908086831309554\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.33      0.50        21\n",
            "           1       0.84      0.87      0.85        54\n",
            "           2       0.90      0.95      0.93        78\n",
            "           3       0.89      0.89      0.89        83\n",
            "           4       0.94      0.97      0.96       243\n",
            "\n",
            "    accuracy                           0.91       479\n",
            "   macro avg       0.91      0.80      0.83       479\n",
            "weighted avg       0.92      0.91      0.91       479\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prototype Summary\n",
        "\n",
        "We trained a Random Forest classifier on a cleaned student performance dataset.  \n",
        "After splitting into train, validation, and test sets, we achieved the following results:\n",
        "\n",
        "- **Validation Accuracy**: 90.6%\n",
        "- **Test Accuracy**: 91.4%\n",
        "- **Final Weighted F1 Score**: 90.8%\n",
        "\n",
        "The model showed strong predictive performance, especially in identifying students at risk of failing (Grade F).  \n",
        "This establishes a solid baseline for future improvements, such as hyperparameter tuning or trying different classifiers.\n"
      ],
      "metadata": {
        "id": "VnG1sXkDyc2K"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}